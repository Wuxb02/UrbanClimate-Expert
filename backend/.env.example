# ========================================
# UrbanClimate-Expert 环境配置模板
# ========================================
# 使用说明:
# 1. 复制本文件为 .env
# 2. 根据实际环境填写配置值
# 3. 不要将 .env 提交到版本控制系统
# ========================================

# ========================================
# LLM 配置
# ========================================

# LLM 类型: "ollama" 或 "openai"
LLM_TYPE=ollama

# ----------------------------------------
# Ollama 配置 (当 LLM_TYPE=ollama 时使用)
# ----------------------------------------
# Ollama API 端点 (默认本地服务)
OLLAMA_BASE_URL=http://localhost:11434/v1

# Ollama 模型名称
# 推荐模型:
#   - qwen2.5:14b (中文能力强,推荐)
#   - llama3:8b (英文为主,速度快)
#   - mistral:7b (平衡性能)
OLLAMA_MODEL=qwen2.5:14b

# ----------------------------------------
# OpenAI 配置 (当 LLM_TYPE=openai 时使用)
# ----------------------------------------
# OpenAI API Key (必填,从 https://platform.openai.com/api-keys 获取)
OPENAI_API_KEY=

# OpenAI API 端点 (可选,默认为官方端点)
# 使用代理或第三方服务时填写
OPENAI_BASE_URL=

# OpenAI 模型名称
# 推荐模型:
#   - gpt-4o-mini (性价比高,推荐)
#   - gpt-4o (能力最强,成本较高)
#   - gpt-3.5-turbo (速度快,成本低)
OPENAI_MODEL=gpt-4o-mini

# ========================================
# LightRAG 配置
# ========================================

# LightRAG 工作区路径 (相对于 backend 目录)
# 存储 chunks.json, entities.json, graph.graphml 等文件
LIGHTRAG_WORKSPACE=./data

# LightRAG 超时配置 (秒)
# LLM 调用超时:
#   - 本地大模型 (32B+): 建议 600-900 秒
#   - 本地中型模型 (7B-14B): 建议 300-600 秒
#   - 云端 API (OpenAI/阿里云等): 建议 180-300 秒
LLM_TIMEOUT=600

# Embedding 调用超时:
#   - 本地模型: 建议 60-120 秒
#   - 云端 API: 建议 30-60 秒
EMBEDDING_TIMEOUT=120

# ========================================
# Rerank 配置 (可选,用于提升检索质量)
# ========================================

# 是否启用 Rerank 功能 (默认 false)
# 启用后可显著提升查询结果的相关性,但会增加 API 调用成本
ENABLE_RERANK=false

# Rerank 模型名称 (推荐使用 Cohere 的 rerank-v3.5)
RERANK_MODEL=rerank-v3.5

# Rerank API Key (从 https://cohere.com 获取)
RERANK_API_KEY=your-cohere-api-key-here

# Rerank API 端点 (默认 Cohere 官方端点)
RERANK_BASE_URL=https://api.cohere.com/v2/rerank

# 是否启用分块 (对于有 token 限制的模型,设为 true)
RERANK_ENABLE_CHUNKING=false

# 每个文档的最大 token 数 (默认 4096)
RERANK_MAX_TOKENS_PER_DOC=4096

# ========================================
# 数据库配置 (Phase 2)
# ========================================

# MySQL 数据库连接
# 格式: mysql+aiomysql://用户名:密码@主机:端口/数据库名
# 请根据实际环境修改用户名、密码和数据库名
MYSQL_DSN=mysql+aiomysql://root:password@localhost:3306/urban_climate

# Neo4j 图数据库配置 (Phase 4 需要,暂时可选)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j-password

# ========================================
# 文件存储配置 (Phase 2)
# ========================================

# 上传文件存储目录 (相对于 backend 目录)
UPLOAD_DIR=./uploads

# 单文件最大大小(MB)
MAX_FILE_SIZE_MB=100

# ========================================
# Redis 配置 (Phase 5 使用)
# ========================================
# REDIS_URL=redis://localhost:6379/0

# ========================================
# 应用配置
# ========================================

# FastAPI 调试模式 (生产环境设为 false)
DEBUG=true

# 允许跨域的来源 (逗号分隔,生产环境需指定具体域名)
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# ========================================
# 日志配置
# ========================================

# 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
